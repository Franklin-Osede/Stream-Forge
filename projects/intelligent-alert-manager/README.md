# ğŸš¨ Intelligent Alert Manager

> **Sistema de alertas inteligentes con ML.**

## ğŸ“‹ **DescripciÃ³n**

Intelligent Alert Manager es un sistema avanzado de gestiÃ³n de alertas que utiliza machine learning para reducir el alert fatigue, agrupar alertas similares y proporcionar escalaciÃ³n automÃ¡tica inteligente.

## ğŸ› ï¸ **Stack TecnolÃ³gico**

- **Backend**: Python + FastAPI
- **ML**: TensorFlow + Scikit-learn
- **Caching**: Redis + Celery
- **Streaming**: Kafka + Kafka Consumer
- **Observabilidad**: Prometheus + Grafana
- **ContainerizaciÃ³n**: Docker

## ğŸš€ **CaracterÃ­sticas**

- âœ… Clustering de alertas similares
- âœ… PredicciÃ³n de alertas basada en patrones
- âœ… EscalaciÃ³n automÃ¡tica inteligente
- âœ… IntegraciÃ³n con Slack/Discord/Teams
- âœ… Dashboard de gestiÃ³n de alertas
- âœ… API REST para configuraciÃ³n
- âœ… MÃ©tricas de efectividad

## ğŸ“Š **Arquitectura**

```mermaid
graph LR
    A[Alert Sources] --> B[Alert Ingestion]
    B --> C[ML Classifier]
    C --> D[Alert Clustering]
    D --> E[Escalation Engine]
    E --> F[Notification Channels]
    G[Pattern Learning] --> C
    H[Feedback Loop] --> G
```

## ğŸ”§ **ConfiguraciÃ³n**

### **Variables de Entorno**

```bash
# Redis
REDIS_URL=redis://redis:6379
REDIS_DB=0

# Kafka
KAFKA_BROKERS=localhost:9092
KAFKA_TOPIC_ALERTS=alert-events
KAFKA_GROUP_ID=alert-manager

# Prometheus
PROMETHEUS_URL=http://prometheus:9090
PROMETHEUS_QUERY_TIMEOUT=30s

# Notificaciones
SLACK_WEBHOOK_URL=https://hooks.slack.com/...
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/...
TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/...

# ML
MODEL_PATH=/app/models
RETRAIN_INTERVAL=3600
CLUSTERING_THRESHOLD=0.8
```

### **Endpoints de API**

```yaml
POST /api/v1/alerts                    # Crear alerta
GET  /api/v1/alerts                    # Listar alertas
GET  /api/v1/alerts/{id}               # Obtener alerta
POST /api/v1/alerts/{id}/acknowledge   # Reconocer alerta
POST /api/v1/alerts/{id}/resolve       # Resolver alerta
GET  /api/v1/clusters                  # Clusters de alertas
POST /api/v1/rules                     # Crear regla
GET  /api/v1/metrics                  # MÃ©tricas
GET  /api/v1/health                   # Health check
```

## ğŸš€ **Inicio RÃ¡pido**

```bash
# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env

# Descargar modelos ML
make download-models

# Levantar en desarrollo
make up

# Ver logs
make logs
```

## ğŸ¤– **Algoritmos ML**

### **1. Clustering de Alertas**
- **Algoritmo**: DBSCAN + K-Means
- **PropÃ³sito**: Agrupar alertas similares
- **Features**: Severidad, servicio, mensaje, timestamp

### **2. PredicciÃ³n de Alertas**
- **Algoritmo**: LSTM + Random Forest
- **PropÃ³sito**: Predecir alertas futuras
- **Features**: Patrones histÃ³ricos, mÃ©tricas del sistema

### **3. ClasificaciÃ³n de Severidad**
- **Algoritmo**: Gradient Boosting
- **PropÃ³sito**: Clasificar automÃ¡ticamente la severidad
- **Features**: Contenido del mensaje, contexto, historial

## ğŸ“ˆ **MÃ©tricas de Alertas**

- `alerts_received_total`
- `alerts_clustered_total`
- `alerts_resolved_total`
- `alert_resolution_time_seconds`
- `false_positive_rate`
- `alert_fatigue_score`

## ğŸ§ª **Testing**

```bash
# Tests unitarios
pytest tests/unit/

# Tests de integraciÃ³n
pytest tests/integration/

# Tests de ML
pytest tests/ml/

# Coverage
pytest --cov=src tests/
```

## ğŸ“š **API Documentation**

### **Crear Alerta**

```bash
curl -X POST http://localhost:8002/api/v1/alerts \
  -H "Content-Type: application/json" \
  -d '{
    "title": "High CPU Usage",
    "description": "CPU usage is above 90%",
    "severity": "warning",
    "service": "event-bridge-kafka",
    "labels": {
      "instance": "kafka-1",
      "environment": "production"
    }
  }'
```

### **Clustering de Alertas**

```bash
curl -X GET "http://localhost:8002/api/v1/clusters?service=event-bridge-kafka&limit=10"
```

### **Configurar Regla de EscalaciÃ³n**

```bash
curl -X POST http://localhost:8002/api/v1/rules \
  -H "Content-Type: application/json" \
  -d '{
    "name": "High CPU Escalation",
    "condition": "severity == \"critical\" AND service == \"event-bridge-kafka\"",
    "escalation": {
      "delay": 300,
      "channels": ["slack", "email"],
      "recipients": ["oncall@company.com"]
    }
  }'
```

## ğŸ” **Monitoreo**

### **Health Check**

```bash
curl http://localhost:8002/api/v1/health
```

### **MÃ©tricas**

```bash
curl http://localhost:8002/api/v1/metrics
```

### **Dashboard Grafana**

El proyecto incluye dashboards pre-configurados para:
- Alertas activas por servicio
- Tendencias de alertas
- Efectividad del clustering
- MÃ©tricas de resoluciÃ³n

## ğŸ³ **Docker**

```bash
# Construir imagen
docker build -t streamforge/intelligent-alert-manager .

# Ejecutar contenedor
docker run -p 8002:8000 \
  -e REDIS_URL=redis://redis:6379 \
  -e KAFKA_BROKERS=localhost:9092 \
  -v $(pwd)/models:/app/models \
  streamforge/intelligent-alert-manager
```

## ğŸ“ **Estructura del Proyecto**

```
intelligent-alert-manager/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # FastAPI endpoints
â”‚   â”œâ”€â”€ ml/               # Modelos ML
â”‚   â”‚   â”œâ”€â”€ clustering/   # Clustering algorithms
â”‚   â”‚   â”œâ”€â”€ prediction/   # Prediction models
â”‚   â”‚   â””â”€â”€ classification/ # Classification models
â”‚   â”œâ”€â”€ processors/        # Procesadores de alertas
â”‚   â”œâ”€â”€ notifiers/        # Notificadores
â”‚   â””â”€â”€ utils/            # Utilidades
â”œâ”€â”€ models/               # Modelos ML entrenados
â”œâ”€â”€ data/                 # Datos de entrenamiento
â”œâ”€â”€ tests/                # Tests
â””â”€â”€ docker/              # ConfiguraciÃ³n Docker
```

## ğŸ¯ **Casos de Uso**

### **ReducciÃ³n de Alert Fatigue**
- Agrupar alertas similares
- Filtrar alertas irrelevantes
- Priorizar alertas crÃ­ticas

### **EscalaciÃ³n Inteligente**
- EscalaciÃ³n automÃ¡tica basada en patrones
- Notificaciones contextuales
- GestiÃ³n de turnos de guardia

### **AnÃ¡lisis Predictivo**
- Predecir alertas futuras
- Identificar patrones de fallos
- Optimizar recursos de guardia

## ğŸ”§ **ConfiguraciÃ³n Avanzada**

### **Clustering**
```yaml
# ConfiguraciÃ³n de clustering
clustering:
  algorithm: dbscan
  eps: 0.5
  min_samples: 2
  features: [severity, service, message_similarity, time_proximity]
```

### **Notificaciones**
```yaml
# ConfiguraciÃ³n de notificaciones
notifications:
  slack:
    webhook_url: ${SLACK_WEBHOOK_URL}
    channel: "#alerts"
    username: "AlertManager"
  email:
    smtp_host: smtp.gmail.com
    smtp_port: 587
    username: ${EMAIL_USER}
    password: ${EMAIL_PASSWORD}
```

## ğŸ¤ **Contribuir**

1. Fork el proyecto
2. Crea tu feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la branch (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ **Licencia**

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

---

**Parte del ecosistema StreamForge** ğŸš€
